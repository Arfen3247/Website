<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="styles.css" />
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <nav>
      <ul class="nav-bar">
        <li><a href="index.html">Home</a></li>
      </ul>
    </nav>

    <section>
      <h1>University Projects</h1>

      <button class="accordion_cover">
        <h3>Master's Thesis — Kernel Density Estimation</h3>
      </button>
      <div class="accordion_panel">
        <p>
          In the summer of 2025 I completed a research project in Mathematics as
          the last third of my Master's degree. This consisted of a
          <a href="Files/Projects/MSc_Thesis_Adam.pdf">thesis</a> and a
          <a href="Files/Projects/MSc_Presentation_Adam.pdf">presentation</a>.
          For this, I studied Kernel Density Estimation. This is a method in
          non-parametric statistics to recover a probability density function
          from a sample, without placing restrictive assumptions on the density.
          In particular, I studied the convergence rates of these estimators,
          under some regularity assumptions on the density. The thesis is split
          into two parts. The first explores the problem in the classic setting,
          on the real line, and follows
          <a href="https://link.springer.com/book/10.1007/b13794">this book</a>
          by Tsybakov. The second half considers the problem on more general
          metric spaces and catches up to some modern research done by my
          supervisor
          <a href="https://sites.google.com/site/galatiacleanthous/home"
            >Dr. Galatia Cleanthous</a
          >
          and her collaborators. This project earned a grade of 91%.
        </p>
      </div>
      <button class="accordion_cover">
        <h3>Undergraduate II — Thermal Creation of Solitons</h3>
      </button>
      <div class="accordion_panel">
        <p>
          In 2024 (the third year of my undergraduate), my classmate
          <a href="https://www.linkedin.com/in/cillian-grall/">Cillian Grall</a>
          and I completed a project on the thermal creation of
          <a href="https://en.wikipedia.org/wiki/Soliton"> solitons</a>. These
          are long-surviving, localised, non-linear wave-packets that appear in
          a scalar field subject to a multi-welled potential, where part of the
          field spills into another well. Our setting is some scalar field
          \(\phi(\vec{x},t)\) subject to the wave equation and a potential well
          \(V(\phi)\),$$ \frac{\partial^2\phi}{\partial t^2} = \nabla^2\phi -
          \frac{d V}{d\phi}.$$ We focused on the simplest case, a
          one-dimensional scalar field \(\phi\) with a double-welled quartic
          potential \(V(\phi)=\lambda(\phi^2-1)^2\), where \(\lambda\) is a
          coupling parameter. The system was discretised and subjected to
          periodic boundary conditions. This discretised system then acts as a
          pearl necklace, with each pearl moving with its own speed, being
          pulled down the walls of the potential, and tugging on its neighbours.
          Adding enough energy in the system allows some section of the necklace
          to cross the divide into the other well. This forms a large wave in
          the field whcih survives until the pearls happen to spill back over —
          a soliton! For a range of temperatures, the system was initialised
          using a
          <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">
            Markov Chain Monte Carlo</a
          >
          approach, called the Heat Bath Algorithm. (This was quite difficult,
          and I am still hugely proud of it.) The system was then evolved simply
          using the finite difference method, and the creation rate of solitons
          was calculated, and graphed against temperature. The code can be found
          <a href="https://github.com/Arfen3247/Solitons">here</a>, and the
          report <a href="Files/Projects/Kink_Anti_kink_creation.pdf">here</a>.
          This project earned a grade of 87%.
        </p>
      </div>
      <button class="accordion_cover">
        <h3>Undergraduate I — The Chaotic Inflationary Universe</h3>
      </button>
      <div class="accordion_panel">
        <p>
          In 2023 (the second year of my undergraduate), my classmates
          <a href="https://www.linkedin.com/in/cillian-grall/">Cillian Grall</a
          >,
          <a href="https://www.linkedin.com/in/ciaran-macnamara-66786b381/"
            >Ciaran McNamara</a
          >
          and I completed a project on the inflation of the early universe.
          There are properties of our universe which seem unlikely, such as its
          apparent flatness, but become credible if the universe underwent a
          huge spatial growth in a short period of time. This idea is called
          <a href="https://en.wikipedia.org/wiki/Cosmic_inflation"
            >Cosmic Inflation</a
          >. It is estimated that at least 60 e-folds of inflation must have
          occurred. That is to say, points in space 1 unit apart would be
          separated by \(e^{60}\approx 10^{26}\) units after some finite time.
          Quite a lot! If we pick a pair of points in space, and track the
          distance between them over time, calling this function the cosmic
          scale factor \(a(t)\), we can interpret this as a measure of the
          universe's size over time. In this project, we assumed a flat universe
          dominated by a scalar field \(\phi(t)\), obeying the Friedman and
          Klein-Gordon equations, $$H := \frac{\dot{a}}{a} =
          C\sqrt{\frac{1}{2}\dot{\phi}^2 + V(\phi)}, \qquad
          \ddot{\phi}+3H\dot{\phi}+\frac{dV}{d\phi}=0,$$where
          \(C=M_p^{-1}\sqrt{8\pi/3}\) and \(M_p\) is the Planck length. We focus
          on the simplest potential, the quadratic well
          \(V(\phi)=\frac{1}{2}m^2\phi^2\). The Friedman equation causes \(a\)
          to increase rapidly when \(\phi\) or \(\dot{\phi}\) are large. The
          Klein-Gordon equation causes \(\phi\) to act roughly like a damped
          oscillator, and decay towards the minimum of \(V\). Together, these
          causes \(\phi\) to slowly settle towards the minimum and \(a\) to grow
          until that time. This leads to a finite period of time where intense
          growth is observed — cosmic inflation! Choosing some inital conditions
          of \(\phi\) and \(\dot{\phi}\), the system can be evolved over time
          (using an ODE solver) to see how much inflation occurs. In this
          project, we explored which initial conditions of led to a sufficient
          amount of inflation, finding this is easier than expected under our
          simple model. We also attempted to study the impact of the mass
          parameter \(m\), and even some different potentials \(V\). The Python
          code can be found
          <a href="https://github.com/Arfen3247/Chaotic-Inflation">here</a>, and
          the report
          <a href="Files/Projects/Chaotic_Inflation_Report.pdf">here</a>.
          Looking back on it now, this project <s>was quite crap</s> could have
          been done better. But it was our first, so don't judge it too harshly!
        </p>
      </div>

      <h1>Personal Projects</h1>
      <button class="accordion_cover">
        <h3>My Website</h3>
      </button>
      <div class="accordion_panel">
        <p>
          My ongoing project, starting August 2025, is making
          <a href="https://adamfurlong.me/">my own website</a>. It will be a
          place for me to talk about things I like, mainly some
          <a href="https://adamfurlong.me/Projects.html">Projects</a> of mine
          such as <a href="https://adamfurlong.me/">my website</a>.
        </p>
        <p>
          Hilarious self-references aside, this has been a really fun project.
          <a href="https://github.com/Arfen3247/Website">Here</a> is the
          repository, if you interested in how it works. It started as a theft
          of <a href="https://www.patrykdrozd.fun/">my friend's website</a>,
          because his is pretty cool (and I liked the colour cheme). It is
          hosted for free using GitHub Pages. The only cost would be getting
          your own personalised domain name. I got mine from
          <a href="https://porkbun.com/">here</a>, for about 20 euro a year, but
          there are many such sites. As I build more of it, I might have more to
          say...
        </p>
      </div>
      <p>
        The following are 'ready' soon, I am in the process of writing them up.
      </p>

      <button class="accordion_cover">
        <h3>A Numberplate Game</h3>
      </button>
      <div class="accordion_panel">
        <p>
          Here is a game a friend taught me on the drive to university, that
          spawned some questions I answered by using python.
        </p>
        <h3>The Game</h3>
        <p>
          A <b>digit string</b> is an ordered list of numbers (integers from 0
          to 9 in our case), such as 15397. This is not to be interpreted as
          fifteen thousand three hundred and ninety seven, but as one followed
          by five, three, nine, and seven.
        </p>
        <p>
          \(1\times (5-3)+9\div 7\) is an <b>expression</b> of the digit string
          15397. Between the digits we place some operation from addition,
          subtraction, multiplication and division. We are allowed to use an
          operation as many times as we like (including not at all), to use as
          many parentheses as we like, but we cannot reorder the digits and
          every two digits must have an operation between them.
        </p>
        <p>
          A <b>solution</b> of the digit string is some expression that
          evaluates to zero. Note that \(9-9\), \(1+2-3\), \(8-2\times 4\) and
          \(2-6\div (1+2)\) are solutions of 99, 123, 824 and 2612 respectively.
          Clearly any digit string which contains a zero can be solved using
          only multiplications. Eg. \(5\times0\times3\) is a solution of 503.
          \(1\times (5-3)+9\div 7\) is clearly not a solution to 15397, but can
          you find one? <span class="spoiler">\((1+5+3-9)\times7\)</span>
        </p>
        <p>
          Given some source of digit strings, the game is to be the first to
          find a solution. For example, Irish vehicle registration plates
          (numberplates) take the form 162-D-15397. On the drive to university,
          we would play the game on the other cars around us. I won slightly
          more often (he was driving).
        </p>
        <h3>Some questions</h3>
        <p>
          Firstly, how many digit strings can be solved? This answer is quite
          clearly infinity. Since 11 is solvable, so is anything that contains
          11, such as 4627115, of which there are infinitely many. The second
          question is less obvious.
        </p>
        <p>
          Some strings cannot be solved. For example, 1, 12, 124, 8985. How many
          cannot be solved? As strings get longer, it becomes easier to solve
          them, so we expect the unsolvable strings to get increasingly rare.
          But, are there only finitely many of them? If so, what is the largest
          of them? Have a think about it.
        </p>
      </div>

      <button class="accordion_cover">
        <h3>Coin Flipping in an Interval</h3>
      </button>
      <div class="accordion_panel">
        <p>An interesting probability question I worked on!</p>
      </div>

      <button class="accordion_cover">
        <h3>the Irrelevant Round Problem</h3>
      </button>
      <div class="accordion_panel">
        <p>An interesting probability question I worked on!</p>
      </div>
      <p>
        The following are nowhere near ready, so don't expect an update anytime
        soon. Feel free to ask me about them though, I have thought about them a
        lot, and have some scraps written in places.
      </p>
      <!--  
      <button class="accordion_cover">
        <h3>VAMPs — Violators of A Monotonic Property</h3>
      </button>
      <div class="accordion_panel">
        <p>
          I was feeling particularly like a cosmologist when I named this :)
          There is a family of enumeration problems such as the Numberplate Game
          above, where the digit strings we are looking for naturally form a
          Trie structure. Instead of searching through all digit strings, we
          need only search through this tree. For example, by depth-first or
          breadth-first seacrhes, which have their own advantages.
        </p>
        <img
          src="images/Project/Trees/tree_basic.jpg"
          alt="tree_basic"
          style="width: 300px"
        />
        <p>
          I am interested in the breadth-first approach. At the cost of holding
          the whole Trie in memory, we can construct an enumeration algorithm
          with significantly improved time complexity. Admittedly, in most cases
          this is largely useless, as the memory cost gives a ceiling to how
          many terms of the sequence can be reached. The ones it does reach
          though, it reaches far faster than similar methods.
        </p>

        <p>
          This serves as a sequel to the Numberplate Game above, so I'll finish
          that first!
        </p>
      </div>
    -->

      <button class="accordion_cover">
        <h3>Rubik's Cube — Last Layer Lunatics</h3>
      </button>
      <div class="accordion_panel">
        <!--  
        <p>
          While I am no longer a speedcuber, from time to time I still fidget
          with and think about Rubik's cubes. The last step in many method of
          solving the cube is the last layer. There are in essence 4 objectives:
          to orient and permute the corners and edges. While more advanced
          methods can complete more than one of these objectives in single
          stages, many beginner's methods are split into these 4 stages, using
          some algorithm to complete each. This is called '4-look last layer',
          or 4LLL, and is really the minimum number of algorithms required to
          solve the cube. These algorithms essentially give a directed graph
          structure to the set of states of the last layer. A true beginner may
          not know how to efficiently traverse this graph, and may choose paths
          which loop back on themselves. With experience, one learns to
          distinguish between these states. However, by this time, one learns
          more algorithms to deal with these cases in a more efficient way,
          moving towards a faster 2LLL method and removing the need for
          efficient graph traversal. My question is then this rather unimportant
          one: how move-efficient can you get using only the 4LLL algorithms? On
          this graph structure they define, what are the optimal paths to the
          solved state, and what is the average number of moves required?
          Answering these questions can be done using a Breadth-First Search
          backwards from the solved state, which can be implemented in a quick
          python script...
        </p>
        -->
        <p>
          Using only a limited number of algorithms, like those of a
          4-Look-Last-Layer approach, what is the average number of moves needed
          to solve the last layer of a Rubik's cube? These algorithms would link
          the last-layer states into a connected graph, and this question can be
          answered by traversing the graph to, or from, the solved state. A
          simple project, that I haven't found time to work on yet...
        </p>
      </div>

      <button class="accordion_cover">
        <h3>Contour Integration as a Root-Finding Method</h3>
      </button>
      <div class="accordion_panel">
        <p>This is a really bad method.</p>
        <p>
          Root-finding is the problem of finding where a function is zero. In
          the diagram below, it means finding where the curve crosses the
          \(x\)-axis. This location is called the root, and is denoted \(x_0\).
          Sometimes, we cannot solve this exactly, and must turn to numerically
          approximating it. There are many good methods to do this. Using \(N\)
          evaluations, the bisection method can achieve an error that is
          \(\mathcal{O}(2^{-N})\), and assuming the function is 'nice', there
          are much faster methods available.
        </p>
        <img class="centre" src="images/root_finding.jpg" style="width: 50%" />
        <p>
          To use this new method, we must place several strong assumptions on
          the function \(f\). First, there exists a complex extension of \(f\)
          on some known open subset \(U\subset\mathbb{C}\) that contains the
          root \(z_0\) we want. Second, we can construct some loop \(\gamma\)
          within \(U\) that encloses \(z_0\). We also need the winding number of
          \(\gamma\) about \(z_0\) to be 1, and for \(z_0\) to be zero of order
          one of \(f\).
        </p>
        <p>
          Here is a schematic diagram of the complex plane around the root
          \(z_0\). The dashed line represents the boundary of \(U\). Within this
          region, \(f\) is assumed to be holomorphic (very very smooth and
          nice). The loop \(\gamma\) is within \(U\), and goes around \(z_0\)
          once, counter-clockwise.
        </p>
        <img
          class="centre"
          src="images/root_finding_2.jpg"
          style="width: 50%"
        />
        <p>
          Then, if we integrate \(z/f(z)\) and \(1/f(z)\) along the curve
          \(\gamma\), the resulting ratio will be the root we are looking for!
        </p>
        $$\left.\oint_\gamma\frac{z}{f(z)}dz \right/
        \oint_\gamma\frac{1}{f(z)}dz = z_0 $$
        <p>
          This is called a coutour integral, where \(\gamma\) is the contour.
          Evaluating these can be fun, but most analytic methods revolve around
          knowing the singularities of the integrand. That is, where the
          function to be integrated diverges. In this case, there is exactly
          one, and it is \(z_0\)... but we don't know where it is!
          <i>That is the whole point!</i> So we must turn to numerical
          approximation.
        </p>
        <p>
          This still doesn't sound too awful. Just numerically approximate the
          integral, and this will still approximate the root. Using a smooth
          contour \(\gamma\), and numerically integrating using the trapezoid
          method with \(N\) evaluations, we can show that the resulting error
          will drop faster than all powers of \(N\). What we cannot do, however,
          is guarantee that the error will drop faster than that of the
          bisection method. Which is embarrassing, as that is perhaps the most
          simple root-finding algorithm, and this is far, far more expensive!
        </p>
        <p>
          So from both analytical and numerical points of view, this method is
          useless. But because it pops out of some really nice maths, it gets
          rediscovered from time to time. It got a bit of media fanfare when it
          was used offhand in
          <a href="https://link.springer.com/article/10.1007/s00283-020-09966-0"
            >this paper</a
          >
          from 2020. The author derived a transcendental equation, the root of
          which was a number that solved
          <a
            href="https://en.wikipedia.org/wiki/Goat_grazing_problem#Interior_grazing_problem"
            >the Grazing Goat problem</a
          >
          . At the end, the author constructs such an integral from the
          equation, and claims this is a <i>"closed-form solution"</i> for the
          root. I have strong opinions on this wording — it is a load of shite.
          Perhaps I will elaborate sometime...
        </p>
        <p>
          Anyway, despite the fact the method is terrible, I did spend some time
          thinking about how to improve it. The rough goal is to
          <i>steel-man</i> the method — to make a stronger version of it, and
          then to demonstrate this stronger version is still bad. (If you want
          some spoilers, ask me.)
        </p>
      </div>

      <p>
        If you have any problems you think I would enjoy, please do share ;)
      </p>
    </section>

    <!-- Footer -->
    <footer>&copy; Adam Furlong September 2025. All rights reserved.</footer>
  </body>

  <!-- Accordion -->
  <script>
    var acc = document.getElementsByClassName("accordion_cover");
    var i;

    for (i = 0; i < acc.length; i++) {
      acc[i].addEventListener("click", function () {
        this.classList.toggle("active");
        var panel = this.nextElementSibling;
        if (panel.style.display === "block") {
          panel.style.display = "none";
        } else {
          panel.style.display = "block";
        }
      });
    }
  </script>
</html>
